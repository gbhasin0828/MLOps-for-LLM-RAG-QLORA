# -*- coding: utf-8 -*-
"""pytest.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HvPJOn_rZBzVpmrBzoSx3_yUWhjHB0Cm
"""

import pytest
from sentence_transformers import SentenceTransformer, util

embedding_model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")

@pytest.fixture
def mock_rag_pipeline():
  class MockRAGPipeline:
    def generate_response(self, query, context):
      return f"The best promotion strategy is {context[0]['text']}"

      return MockRAGPipeline()

def test_rag_response_quality(mock_rag_pipeline):
  query = "What is the best promotion strategy for item_177?"

  context = [
      {
          "id" : "doc1",
          "score" : 0.9,
          "text" : "Running a 10% discount increases sales."
      },

      {   "id": "doc2",
          "score" : 0.8,
          "text": "Run a BOGO"

      } ]

# AI-Generated Response
generated_response = mock_rag_pipeline.generate_response(query, context)

    #Expected Response (Manually Extracted from Retrieved Data)
expected_response = f"The best promotion strategy is: {context[0]['text']}"

    #Convert both responses to embeddings
generated_embedding = embedding_model.encode(generated_response, convert_to_tensor=True)
expected_embedding = embedding_model.encode(expected_response, convert_to_tensor=True)

    # Compute similarity score (cosine similarity)
similarity_score = util.pytorch_cos_sim(generated_embedding, expected_embedding).item()

    # Check if AI used the retrieved context correctly (Threshold: 80%)
assert similarity_score > 0.8, f"Generated response is not similar enough. Score: {similarity_score}"