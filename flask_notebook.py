# -*- coding: utf-8 -*-
"""Flask_Notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wh7V2dha9EQzCmfmmqmwPgjCbOLzYsTK
"""

pip install pinecone-client

from flask import Flask, request, jsonify, render_template
from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel
from sentence_transformers import SentenceTransformer
import json
import pinecone

from pinecone import Pinecone

# Initialize Pinecone with API key
pc = Pinecone(
    api_key="pcsk_43az94_UYXwwFSRQ6cKeePBZ7sfu5hpHnJUv8UMaXRMvSDaDTvMZBGchNaEL7ESBHt4Jju",
)

# Connect to the existing index
index_name = "trade-data-embeddings"
index = pc.Index(index_name)

embedding_model_name = "sentence-transformers/multi-qa-mpnet-base-dot-v1"
embedding_model_tokenizer = AutoTokenizer.from_pretrained(embedding_model_name)
embedding_model = AutoModel.from_pretrained(embedding_model_name)

bert_model_name = "bert-base-uncased"
bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)
bert_model = AutoModel.from_pretrained(bert_model_name)

gpt_2_model_name = "gpt2"
gpt_2_tokenizer = AutoTokenizer.from_pretrained(gpt_2_model_name)
gpt_2_model = AutoModelForCausalLM.from_pretrained(gpt_2_model_name)

def generate_embeddings_from_base_model(query):
    input_token = embedding_model_tokenizer(query, return_tensors='pt', truncation=True, padding=True, max_length=512)
    return embedding_model(**input_token)

import torch
import json
import pandas as pd

def retrieve_from_pinecone(query, top_k=1):
  query_embedding = generate_embeddings_from_base_model(query)
  query_embedding_list = query_embedding.pooler_output.squeeze().tolist()

  pinecone_result = index.query(
      vector = query_embedding_list,
      top_k = top_k,
      include_metadata = True
  )


  retrieve_context = pinecone_result['matches'][0]['metadata']['json']

  context_dict = json.loads(retrieve_context)

  df = pd.DataFrame([context_dict])


  return df



"""# **Test Query**"""

query = "Give me top 5 promotions for item Item_177 at customer Discount"

"""# **Continue with Flask app**"""

def receive_query_context(query):
  query_embedding = generate_embeddings_from_base_model(query)
  query_embedding_list = query_embedding.pooler_output.squeeze().tolist()

  pinecone_result = index.query(
      vector = query_embedding_list,
      top_k = 5,
      include_metadata = True
  )

  context = [json.loads(res['metadata']['json']) for res in pinecone_result['matches']]

  return context

def generate_top_response(query):
  context = receive_query_context(query)

  context_df = pd.DataFrame(context)

  return context_df

from flask import Flask, request, jsonify, render_template

app = Flask(__name__)

@app.route('/')
def home():
  return render_template('index.html')

@app.route("/process_query", methods = ['POST'])
def process_query():
  query = request.form['query']
  model = request.form['model']

  if model == "sentence-transformers/multi-qa-mpnet-base-dot-v1":
    rresponse = retrieve_from_pinecone(query)

  elif model == "bert-base-uncased":
    rresponse = retrieve_from_pinecone(query)

  elif model == "gpt2":
    response = retrieve_from_pinecone(query)

  else:
    return "Model not found"

  return jsonify({'response' : response})

if __name__ == "main":
  app.run(host = "0.0.0.0", port = 5004, debug = True)

